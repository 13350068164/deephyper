import logging
import os
import signal
import sys
from pprint import pprint
from random import random
from importlib import import_module

import numpy as np
import tensorflow as tf

HERE = os.path.dirname(os.path.abspath(__file__)) # search dir
top  = os.path.dirname(os.path.dirname(HERE)) # directory containing deephyper
sys.path.append(top)

import deephyper.model.arch as a
from deephyper.model.builder.tf import BasicBuilder
from deephyper.model.trainer.tf import BasicTrainer
from deephyper.model.utilities.conversions import action2dict
from deephyper.search import util
from deephyper.search.controller.nas.reinforce.tf import BasicReinforce
from deephyper.model.utilities.nas_cmdline import create_parser


def run(param_dict):
    config = param_dict
    pprint(config)

    load_data = import_module(param_dict['load_data_module_name']).load_data

    # Loading data
    (t_X, t_y), (v_X, v_y) = load_data(dest='MNISTnas')

    config['input_shape'] = list(np.shape(t_X))[1:]

    config[a.data] = { a.train_X: t_X,
                       a.train_Y: t_y,
                       a.valid_X: v_X,
                       a.valid_Y: v_y }

    action = config['arch_seq']
    architecture = action2dict(config, action[0][0])

    # For all the Net generated by the CONTROLLER
    trainer = BasicTrainer(config)

    arch_def = architecture
    global_step = config['global_step']

    # Run the trainer and get the rewards
    reward = trainer.get_rewards(arch_def, global_step)
    result = reward
    #sleep(4)
    #result = np.random.randint(1, 95) + np.random.random()
    print('OUTPUT: ', result)
    return result

if __name__ == '__main__':
    parser = create_parser()
    cmdline_args = parser.parse_args()
    param_dict = cmdline_args.config
    run(param_dict)
