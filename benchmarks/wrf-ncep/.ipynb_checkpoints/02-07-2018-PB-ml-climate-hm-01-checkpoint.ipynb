{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'ml-climate-hm-01'\n",
    "inp_df = pd.read_csv('../data/1980-2005_2d_002_new.txt', sep=\"  \", header=None, engine='python')\n",
    "out_df1 = pd.read_csv('../data/1980-2005_3d_vy_002.txt', sep=r\"\\s*\", header=None, engine='python')\n",
    "out_df2 = pd.read_csv('../data/1980-2005_3d_ux_002.txt', sep=r\"\\s*\", header=None, engine='python')\n",
    "out_df3 = pd.read_csv('../data/1980-2005_3d_wz_002.txt', sep=r\"\\s*\", header=None, engine='python')\n",
    "out_df4 = pd.read_csv('../data/1980-2005_3d_tk_002.txt', sep=r\"\\s*\", header=None, engine='python')\n",
    "out_df5 = pd.read_csv('../data/1980-2005_3d_qv_002.txt', sep=r\"\\s*\", header=None, engine='python')\n",
    "out_df = pd.concat([out_df1, out_df2, out_df3, out_df4, out_df5], axis=1)\n",
    "inp_df = inp_df.iloc[0:72900,:]\n",
    "out_df = out_df.iloc[0:72900,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(inp_df.shape)\n",
    "print(out_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rlevels = 17 # we need 0 to 16 layers\n",
    "nlevels = out_df1.shape[1]\n",
    "nseries = int(out_df.shape[1]/nlevels)\n",
    "tlevels = out_df.shape[1]\n",
    "indices = range(tlevels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(rlevels):\n",
    "    for j in range(nseries):\n",
    "        res.append(indices[i+(nlevels*j)])  \n",
    "    #res.append(indices[i+nlevels])\n",
    "print(res)\n",
    "print(len(res))\n",
    "req_out = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "req_out = [int(x) for x in req_out]\n",
    "# load dataset\n",
    "dataset = out_df\n",
    "print(dataset.shape)\n",
    "values = dataset.values\n",
    "# specify columns to plot\n",
    "groups = req_out\n",
    "if len(req_out) > 60:\n",
    "\tgroups = np.random.choice(groups, 60, replace=False)\n",
    "\tgroups = np.sort(groups)    \n",
    "print(values.shape)\n",
    "i = 1\n",
    "pyplot.figure(figsize=(20, 60), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for group in reversed(groups):\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(values[:, group])\n",
    "\tpyplot.title(\"3d data set\")\n",
    "\tpyplot.title('level = %d'% dataset.columns[group])\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "from importlib import reload\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load dataset\n",
    "out_df_sel = out_df.iloc[:,req_out]\n",
    "n_input = inp_df.shape[1]\n",
    "n_output = out_df_sel.shape[1]\n",
    "\n",
    "#dataset = out_df.iloc[:,1]\n",
    "dataset = pd.concat([inp_df, out_df_sel], axis=1)\n",
    "print(dataset.shape)\n",
    "values = dataset.values\n",
    "#print(values)\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "\n",
    "preprocessor = Pipeline([('stdscaler', StandardScaler()), ('minmax', MinMaxScaler(feature_range=(0, 1)))])\n",
    "reframed = preprocessor.fit_transform(values)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed\n",
    "n_train_hours = 40000\n",
    "n_val_hours = 10000\n",
    "train = values[:n_train_hours, :]\n",
    "validation = values[n_train_hours:(n_train_hours+n_val_hours),:]\n",
    "test = values[n_train_hours+n_val_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, range(n_input)], train[:, range(n_input, n_input+n_output)]\n",
    "validation_X, validation_y = validation[:, range(n_input)], validation[:, range(n_input, n_input+n_output)]\n",
    "test_X, test_y = test[:, range(n_input)], test[:, range(n_input, n_input+n_output)]\n",
    "print(train_X.shape, train_y.shape, validation_X.shape, validation_X.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "groups = range(train_y.shape[1])\n",
    "# plot each column\n",
    "i = 1\n",
    "pyplot.figure(figsize=(20, 60), dpi=80, facecolor='w', edgecolor='k')\n",
    "for group in reversed(groups):\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(train_y[:, group])\n",
    "\tpyplot.title(group)\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "class Metrics(Callback):    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pyplot.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        yhat = model.predict(test_X)\n",
    "        pyplot.subplot(1, 2, 1)\n",
    "        diff = test_y.ravel() - yhat.ravel()\n",
    "        pyplot.hist(abs(diff), bins=100)\n",
    "        pyplot.xlim((0,0.5))\n",
    "        pyplot.subplot(1, 2, 2)\n",
    "        pyplot.boxplot(abs(diff), 1)\n",
    "        pyplot.ylim((0,0.2))\n",
    "        pyplot.show()      \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoded_train_y_norm_sel = encoded_train_y_norm #[:,0]\n",
    "#encoded_test_y_norm_sel = encoded_test_y_norm #[:,0]\n",
    "#encoded_train_y_norm_sel = encoded_train_y_norm_sel.reshape(50000, 1) \n",
    "#encoded_test_y_norm_sel = encoded_test_y_norm_sel.reshape(22900, 1)\n",
    "#train_X = train_X.reshape(50000, 14) \n",
    "#test_X = test_X.reshape(22900, 14) \n",
    "#print(encoded_train_y_norm_sel.shape)\n",
    "#print(encoded_test_y_norm_sel.shape)\n",
    "#print(train_X.shape)\n",
    "#print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 10.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "# checkpoint\n",
    "filepath= '%s_weights.best.hdf5' % tag\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "callbacks_list = [checkpoint, metrics, early_stopping, lrate]\n",
    "callbacks_list = [checkpoint, metrics, early_stopping]\n",
    "#sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nunits = 16\n",
    "dpout = 0.0\n",
    "input_shape = train_X.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(nunits, activation='relu')(inputs)\n",
    "x = Dropout(dpout)(x)\n",
    "x = Dense(nunits, activation='relu')(x)\n",
    "x = Dropout(dpout)(x)\n",
    "x = Dense(nunits, activation='relu')(x)\n",
    "x = Dropout(dpout)(x)\n",
    "x = Dense(nunits, activation='relu')(x)\n",
    "level_0 = Dense(nseries, name='level_0')(x)\n",
    "prev = level_0\n",
    "outputs_list = []\n",
    "outputs_list.append(prev) \n",
    "for i in range(rlevels-1):\n",
    "    merged = concatenate([inputs] + [prev])\n",
    "    x = Dense(nunits, activation='relu')(merged)\n",
    "    x = Dense(nunits, activation='relu')(x)\n",
    "    x = Dense(nunits, activation='relu')(x)\n",
    "    prev = Dense(nseries, name='level_%d' %(i+1))(x)\n",
    "    outputs_list.append(prev)\n",
    "model = Model(inputs=inputs, outputs=concatenate(outputs_list))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename='model_plot_%s.png' % tag\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file=filename, show_shapes=True, show_layer_names=True)\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import Image, display\n",
    "#display(Image(filename, width=1000, height=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "history = model.fit(train_X, train_y, validation_data=(validation_X, validation_y), callbacks=callbacks_list, epochs=1000, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['mean_absolute_error'], label='train')\n",
    "pyplot.plot(history.history['val_mean_absolute_error'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(test_X)\n",
    "diff = test_y.ravel() - yhat.ravel()\n",
    "pyplot.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "pyplot.hist(diff.ravel(), bins=100)\n",
    "pyplot.title(\"error distribution (observed - predicted)\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "pyplot.figure(figsize=(20, 60), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for group in reversed(groups):\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(test_y[:, group], label='observed')\n",
    "\tpyplot.plot(yhat[:, group], label='predicted')\n",
    "\tpyplot.title('level = %d' % group)\n",
    "\tpyplot.ylim(0, 1)\n",
    "\tpyplot.legend()\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "pyplot.figure(figsize=(5, 30), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for group in reversed(groups):\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tdiff = test_y[:, group] - yhat[:, group]\n",
    "\tpyplot.hist(diff.ravel(), bins=100)\n",
    "\tpyplot.title('level = %d' % group)\n",
    "\tpyplot.xlim(-0.2, 0.2)\n",
    "\tpyplot.legend()\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "diff_results = []\n",
    "for group in groups:\n",
    "\tdiff = test_y[:, group] - yhat[:, group]\n",
    "\tdiff.ravel()\n",
    "\tdiff_results.append(diff)\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "pyplot.boxplot(diff_results, notch=True, patch_artist=True)\n",
    "pyplot.ylim(-0.2, 0.2)\n",
    "pyplot.grid(True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(req_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_indices = np.argsort(req_out).tolist()\n",
    "print(req_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reorder_list = [ diff_results[i] for i in req_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "pyplot.boxplot(reorder_list, notch=True, patch_artist=True)\n",
    "pyplot.ylim(-0.2, 0.2)\n",
    "pyplot.grid(True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for level in range(1, rlevels):\n",
    "    start = (5*level) - 5\n",
    "    end = (5*level)\n",
    "    groups = range(start,end)\n",
    "    i = 1\n",
    "    pyplot.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    for group in reversed(groups):\n",
    "        pyplot.subplot(len(groups), 1, i)\n",
    "        pyplot.plot(test_y[:, group], label='observed')\n",
    "        pyplot.plot(yhat[:, group], label='predicted')\n",
    "        pyplot.title('level = %d' % (level))\n",
    "        pyplot.ylim(0, 1)\n",
    "        pyplot.legend()\n",
    "        i += 1\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
